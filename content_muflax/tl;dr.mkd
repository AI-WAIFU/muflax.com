---
title: "tl;dr: muflax"
alt_titles: [muflax, about muflax]
date: 2012-02-05
techne: :rough
episteme: :broken
toc: true
non_cognitive: true
---

**muflax, n**: information whore, hacker, rationalist, anagami, catharsis junkie, not exactly sane

A quick overview of various beliefs. Useful as a [belief dump][Core Dump], but really, muflax just likes filling out profiles about itself. Maybe it's a signaling thing. Who knows.

Epistemology
============

## A priori knowledge?

There is no meaningful distinction between a priori / a posteriori knowledge. There is no such thing as knowledge without experience. Truth is not an independent property of statements, but the ability to use them to anticipate future experiences. In other words, a map is true if I can use it to navigate. It is meaningless to speak about the truth of a map that doesn't have a territory.

## Abstract objects?

Don't exist. Period. Or rather, what do you anticipate either way? Can you point at an abstract object? There isn't even a phenomenon in need of explanation.

## External world?

There is no distinction between internal / external worlds. It's a bad case of dualism. Look at computationalism: if everything is a program, then there is no such thing as a world outside a program. Input/output are simply features *of* programs. There is no *beyond*. Similarly with our existence.

Religion
========

## Religious affiliation?

1/3 Buddhist, 1/3 Christian Atheist, 1/3 Discordian.

## Is there a God?

"[No, dear.][Fry God]"

## Do you serve the gods?

Yes. This is important.

Ontology
========

## Free will?

There is no free will. It isn't even a useful illusion. It just isn't there. Says [Susan Blackmore][Blackmore Free Will]:

> It is possible to live happily and morally without believing in free will. As Samuel Johnson said, "All theory is against freedom of the will; all experience for it." With recent developments in neuroscience and theories of consciousness, theory is even more against it than it was in his time. So I long ago set about systematically changing the experience. I now have no feeling of acting with free will, although the feeling took many years to ebb away.
>
> But what happens? People say I'm lying! They say itâ€™s impossible and so I must be deluding myself in order to preserve my theory. And what can I do or say to challenge them? I have no idea - other than to suggest that other people try the exercise, demanding as it is.
> 
> When the feeling is gone, decisions just happen with no sense of anyone making them, but then a new question arises - will the decisions be morally acceptable? Here I have made a great leap of faith. It seems that when people discard the illusion of an inner self who acts, as many mystics and Buddhist practitioners have done, they generally do behave in ways that we think of as moral or good. So perhaps giving up free will is not as dangerous as it sounds - but this too I cannot prove.

## Materialism? {#materialism}

Materialism is necessarily dualism and false. There has been a recent ret-con of the term materialism to mean "whatever the scientific consensus says". I oppose this move.

*Materialism* means that all there is, is an interaction of matter. We know this to be false. Gravity can't be accounted for (so far), nor can mathematical claims, nor phenomenal experience.

An extension of materialism is *physicalism*, which now also includes fields and other ideas from physics. This improves the situation, but not by much. It's also a very ugly ontology.

All broadly materialistic approaches are necessarily false. You have to start from idealism, assuming (some) mental events as basic. There is no need to introduce non-mental things like "matter".

*Computationalism* is the idea that everything is the computation of an ideal program. This is a much better ontology and it accounts for mathematical claims, all (known) physics and many (all?) anthropic problems. Unfortunately, it doesn't cover phenomenal experience.

Whether computationalism is just incomplete or something entirely new is needed is anyone's guess. I have no strong opinion on the matter.

## Naturalism?

Naturalism is correct, in the sense that there is no "magic" or fundamental "mystery" that can't be resolved.

## Personal identity?

Depends on what you mean by "self". One "self" has a name, a job, status, friends, memories and so on. This one is linguistically constructed. Another has experiences. I have no idea how that one works in detail. If I didn't live in a social context that demanded that I maintain a "self" persona, then I wouldn't even bother at all. I do not have any experience of a "self" in any meaningful way.

I do not know if it is meaningful to say that a person persists over time or if there are many person-moments who are fundamentally disconnected.

## P-Zombies?

The Zombie position can be separated into two distinct ideas, a strong and a weak one.

The strong (and original) position is that of zombies being externally absolutely identical. You couldn't, through no experiment whatsoever, figure out if you are dealing with a zombie or not. Neither could the zombie themselves. This is complete bonkers.

A weaker position, however, is far more interesting. Exactly how necessary is consciousness, really? Could you build something that does more or less the same things as a human, e.g. can reason, use memory, simulate outcomes, talk and so on, but is completely unconscious? Maybe. I strongly suspect that most aspects of the human mind can be implemented in an unconscious way (or already are). As such, assuming all people at all times to be conscious is almost certainly false.  Exactly what role consciousness plays, however, I don't know.

Morality
========

(See the category [Morality][] for detailed thoughts.)

## Meta-Ethics?

No established position, but closest to deontology or atheistic divine command theory. Yes, I'm aware of the contradiction.

## Moral Realism?

Yes. Being Moral is not a personal preference, not a choice, not a confusion. 

## Cognitivism?

Mostly yes.

## Newcomb's problem: one box or two boxes?

The only two reasons to ever pick two boxes, as I see it, are that you either don't trust the oracle, in which case you don't understand the question, or that you think you can break causality, in which case, good luck with that.

## Prisoner's Dilemma?

Very tricky situation, no simple answer.

## Trolley problem?

I don't switch. The one has the right to not be harmed by me, regardless of the expected death of the many.

## Vegetarianism?

Animals are [not morally relevant][Vegetarian], so no.

Politics
========

The Enlightenment was a huge catastrophe and everything after it is worthless (so far). Beyond that, I have no strong opinions (yet).

Science
=======

## Favorite Quantum Physics Interpretation?

Anything besides Copenhagen. I am not a physicist, so I don't favor anything besides that.

## Great Filter?

Probably valid, probably late, most likely the result of progress being extremly hard.
