---
title: Some Thoughts on Bicameral Minds
date: '2012-01-04'
tags:
- bicameral
- consciousness
- jaynes
techne: :done
episteme: :speculation
slug: 2012/01/04/some-thoughts-on-bicameral-minds/
---

<em>This is a reply to wallowinmaya's comment on my last article. I noticed I kinda wrote an article in disguise, so I'm posting it as one.</em>
<blockquote>The multiple-personality thing is really fascinating. Do you think it’s been a feature or a bug, all things considered? It seems to me that basically everyone has multiple personalities but only one of them is conscious. Your deep acquaintance with your subconsciousness also explains that you endorse wireheading because most usually “subconscious parts” probably find it good. It’s only our conscious, ideal and altruistic self that is against it. Am I totally wrong about this? And if our multiple personalities really have conflicting values that would probably render solutions to moral problems like CEV void, right?</blockquote>
I tend to think of it as a feature, but I'm really used to it, so I'm not exactly an impartial judge. Maybe I'm even less functional and inconsistent than the average person, I don't know. I also don't know if it's really the feature that's unusual or just the way I think about it.

There's a really fascinating book called "The Origin of Consciousness in the Breakdown of the Bicameral Mind" by Julian Jaynes (actually really accessible despite its title and available on library.nu). Basically, he proposes that originally both brain hemispheres were independent minds and that one (the right) commanded the other (the left) through hallucinations, mostly voices. Quote Wiki:
<blockquote>According to Jaynes, ancient people in the bicameral state of mind would have experienced the world in a manner that has some similarities to that of a schizophrenic. Rather than making conscious evaluations in novel or unexpected situations, the person would hallucinate a voice or "god" giving admonitory advice or commands and obey without question: one would not be at all conscious of one's own thought processes per se.</blockquote>
The main problem with this Bicameral Mode is that you can't really self-reflect and function outside of rigid hierarchies. So once civilizations got too large, these bicameral minds collapsed and merged into the modern subjective consciousness. So basically, the evolution goes:

1. monkeys want to track other monkeys, so they develop monkey-simulating hardware
2. monkeys develop language to order other monkeys around
3. one half of a monkey specializes in talking with other monkeys, the other half orders them around (built-in hypocrisy for free!)
4. one half of a monkey orders other half around via hallucinated other monkeys (really dirty hack, but explains all the redundancy between hemispheres)
5. monkeys develop internal pathway so halves can talk more directly

These internalized hallucinated voices we now call "thoughts" and we generally don't believe they come from other monkeys anymore. Because of this, our right hemispheres don't have the ability to speak anymore, but the hardware is still there. It's just not used. (Schizophrenics and people with brain damage in the left hemisphere do use it, though. That's were "God told me to!" comes from.)

Jaynes' point is that the transition from 4. to 5. is almost completely *cultural*. The monkeys in 4. were people like the ancient Babylonians who were obviously capable of writing and everything.

(Side note: I'm really sympathetic to Jaynes' basic argument, but I think his historical argument doesn't actually work out. The effect is probably more subtle than he thinks and the dating is completely off. His main problem - which he totally did not see coming - is that the texts he uses to support his argument (the Old Testament, the Iliad and similar ones) are *much* more recent than he thinks. He follows mainstream scholars at the time, thinking that some parts of the OT are from about 800-700 BCE, with even older oral traditions, but I don't see any evidence for that. I favor *much* later datings. I'd put most of the OT in Hellenistic times (so 300-150 BCE) and large parts of it actually contemporary to the *New* Testament! Almost no historical text that claims an ancient history actually has one. It's bullshit all the way down. But regardless, a weaker form of Jaynes' argument still stands, I think. The contrast in actually-ancient writing (like Babylonian clay tablets) and Hellenistic stuff is striking. Hellenistic culture looks pretty much like ours, but Babylonian culture doesn't seem to have *any* self-reflection. Characters don't think, they don't decide, they mostly follow orders from the gods. I don't know how much of this is just selection bias (great Babylonian novels just didn't survive?), but it really looks like sometime during 5000 BCE and 500 BCE, someone actually had to figure out that you could *think for yourself*, silently, in your own head.)

Anyway. If some basic form of this is true, then there really is no "unified" mind across the whole brain. There's at least two, maybe more. Basically, the hardware is flexible and can support multiple selfs, even simultaneously. Mine just broke a bit and I was stuck with three selfs at the time, or I had greater awareness of already existing ones through an unexpected new connection.

Back to Jaynes' idea, the difference between a "self" and an "other" is really just the level of personal associations and names. They are both hallucinations, in the sense that they run as simulated monkeys on the brain. Making a decision is just simulating a monkey that does something and then seeing what happens, only that we recognize that the simulated monkey is us. (Sometimes we fail the mirror test and that's called "I spoke to someone in a dream". When you have a lucid dream, try switching which person you control.)

This association process is not perfectly reliable. Particularly schizophrenics and people on certain drugs have it fail on them. Quote two schizophrenics in Jaynes' book:
<blockquote>Gradually I can no longer distinguish how much of myself is in me, and how much is already in others. I am a conglomerate, a monstrosity, modeled anew each day.

My ability to think and decide and will to do, is torn apart by itself. Finally, it is thrown out where it mingles with every other part of the day and judges what it has left behind. Instead of wishing to do things, they are done by something that seems mechanical and frightening ... the feeling that should dwell within a person is outside longing to come back and yet having taken with it the power to return.</blockquote>
Jaynes argues pretty convincingly that the left hemisphere, which is normally in charge of interacting with the outside world, can't *refuse* orders in Bicameral Mode. The right side says *anything* and the left side does it. It can't veto orders at all. That would obviously be easy to exploit, so you need to distinguish between "this is a command" and "this is just talk". One heuristic the left side uses is to only recognizes something as an order when it comes from someone higher up in the status hierarchy. So the right side impersonates high-status figures (gods, kings, parents). (There are almost no cases of someone hallucinating low-status characters! No-one thinks they are hearing voices that belong to a random beggar. It's always gods, kings or something equivalent.)

And that's how Bicameral Consciousness works. Both hemispheres already have extensive hardware to simulate people. They need it just to keep up with local status and tribe associations. So they can re-use this hardware by creating fictitious people (often direct copies of real people at first), run them for a bit and see what results they get. They can even interact with these people (i.e. talk with hallucinations). These simulations then ultimately give a direct order and the brain executes it. Achievement unlocked: complex decision making.

(Another side note: that's the reason some people call wakefulness "constrained dreaming". It's the same kind of hallucination process, but there's constant feedback from the outside to guide it, so it looks more consistent. The relevant question is only if there exists a feedback loop between the interpreting part and the generating part. In bicameral minds, thoughts and decisions are *not* connected this way, so they feel like external entities. In modern subjective minds though, we have (some) control over our thoughts - the loop is closed - so it feels internal. This loop is much weaker in practice than most people think though, which is one reason meditation freaks people out. They notice they can't easily make thoughts *stop*.)

But this bicameral setup has one major problem: it's extremely compartmentalized. The left side literally doesn't know what the right side does and vice versa, unless they talk to each other. The cultural hack - modern subjective consciousness - improves on this situation in two ways.

First, *internalize* the simulations. They don't need locations and bodies. Just put them "in your head" somewhere and call them thoughts. (The actual location differs depending on culture, btw.)

Second, talk *constantly*. (Not always literal talk, images work too and so on. Voice-based thought is just the most common.) Meditation people call this the "monkey mind" because it's so hyperactive and out-of-control. But if you don't use it, you literally can't propagate information. You *need* to talk to yourself, in some form or another (which is why I write this novel of a reply), or you can't think.

This finally brings me to the point I wanted to make. I don't think "thoughts" or "selfs" are conscious. Phenomenal consciousness - the one that experiences something - doesn't think and isn't someone. It only *notices* thoughts and selfs. From an phenomenal point of view, there's no difference between "me" or "you" or "Barack Obama". They are all three not conscious, but narrative constructs. So I can have multiple selfs in my head without needing multiple phenomenal consciousnesses. You only need to take care who has executing privileges and who is just talking. (In my case, that's exactly how I malfunction in social contexts. Suddenly all the voices shut up and I have complete radio silence in my head. There is no self, so I can't make any decisions. I just shut up and stare. Which is embarrassing.)

So what really *is* conscious is not the part that has goals or thinks, but the part that models. (Which is why when an experienced meditator stops identifying with things and stops modeling reality, they literally become progressively more unconscious. An ideal samadhi practitioner is indistinguishable from a sleeping one. But "Nirodha Samapatti" sounds so much more sophisticated then "really noticing how I fall asleep".)

(You can completely dissociate from your decision-making process, if you want. It's not particularly difficult. (I stole the idea from Susan Blackmore.) Take a lazy afternoon and try lying down with the intention "I'm not deciding anything today". (Try not to be too tired or you'll just sleep.) Just don't decide anything. You'll lie around for a bit, then get bored. Thoughts come up like, "that's stupid", "I could watch the Daily Show", "I could eat something" and so on. Doesn't matter, not going to decide anything. Eventually - it took me about 5 minutes - you'll move. I suddenly got up and started walking somewhere. "Where the fuck am I going?", I thought. *Something* had decided an action and didn't care about telling me. I found out that I had decided to take a shower. Anyway, you will eventually slip back into *making* decisions. But you don't have to. You can remind yourself that you can just observe and somehow, decisions still happen. They might be stupid and inefficient decisions, but they're still there. No conscious awareness of them whatsoever.)

So based on this, the connection between "consciousness" and "goals" is fairly questionable, I think. At least I personally don't see an obvious way how the two belong together. This brain that is typing this has goals (or something that looks almost like goals, anyway). This brain also experiences things. These two things are independent processes. Why privilege only the goals the phenomenal part notices? With the right kind of practice, I can become conscious or unconscious of pretty much any goal I want. Does that magically change its moral status? Why? (And if so, isn't having no conscious goals ideal?)

(Why privilege only the goals in this brain? Why not fulfill any goal, anywhere, or as much as is feasible at least? What's a "goal" anyway? Has my heart rights? It certainly acts like it doesn't want to stop beating, even if I just try to replace it with a better version. If not, how does a different unconscious piece of carbon suddenly gain rights just because it's in my skull? Damn, morality is so much easier when you belief in "people" as meaningful categories...)

On a related note, I don't know how I feel about wireheading anymore. Some days, I think it's the greatest idea ever, on others it looks like an ethical nightmare. I also don't like that AIXI wireheads itself and so screws up our attempts to enslave it. Makes wireheading look like a huge bug from the outside.

Also:
<blockquote>Your deep acquaintance with your subconsciousness also explains that you endorse wireheading because most usually “subconscious parts” probably find it good. It’s only our conscious, ideal and altruistic self that is against it. Am I totally wrong about this? And if our multiple personalities really have conflicting values that would probably render solutions to moral problems like CEV void, right?</blockquote>
Conflicting values aren't necessarily a big problem in general, I think. The universe is pretty big and there's enough space to satisfy a lot of values at the same time. It would be bad if there were multiple fundamentalists who couldn't accept that anyone else might disagree with them, ever, anywhere.

That's one way I currently think about objective morality - it's an attempt to enforce values when you don't have much power. If my values are Objective(tm), then I have an easy way to force others to comply against their will. (Or at least I can tell myself that, if they only thought rationally, they would have the same values as me.) If all value is subjective and accidental, well, how can I stop someone from eating the wrong kind of ice cream, short of building a Jupiter-sized AI and taking over the universe? So if I were not so insecure, maybe I wouldn't feel so bad about morality.

<em>Anyway. That's the still-in-process thinking I'm currently going through. I'm not sure if I said everything I wanted, but this will have to do for now.</em>