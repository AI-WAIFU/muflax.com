---
title: Logical Fallacies Debunked
date: 2012-04-27
techne: :wip
episteme: :speculation
---

This isn't really a debunking. (I love senselessly hyperbolic titles.) These are actually just some (slightly) prettified notes I made while investigating a certain line of argument.

Rationalist communities are obsessed with logical fallacies and cognitive biases these days[^bias]. However, I'm increasingly seeing the meta-contrarian position that the relevant literature is actually full of bullshit. The two main arguments, as far as I can tell, seem to be that logical fallacies, while often technically correct, don't apply to real-world scenarios by paying attention to very general or contrived cases instead of typical ones, and that bias research is actually methodologically weak and treated as much stronger than is justified.

I don't know anyone whose opinion on these matters I really trust, so I decided to check it out myself. There certainly were some cases where the meta-contrarian argument seemed reasonable, but I didn't know how representative it was. Just because two fallacies aren't actually fallacious doesn't mean that focusing on them fucks up your reasoning, and some r/atheist being an idiot doesn't mean skeptics as a whole are retarded. I started taking notes so I could come to a more complete(-ish) conclusion.

This post is about logical fallacies, cognitive biases will follow soon[^soon].

[^bias]: Which I still find utterly hilarious. RAW was talking about them in the 70s/80s, in a much more reasonable way too, calling out fundamentalist materialists as well (as he called them, though I dislike the label). The fact that the modern transhumanist/rationalist community is entirely pre-dated by batshit-insance mystics who would be downvoted to oblivion today is one of Eris' greatest jokes, I think.

[^soon]: Soon in Valve Time, of course.

Because I'm lazy, I'm basing this off the recent (and quite fancy) [Logical Fallacies Poster][] [^poster] (and because I don't want to grind through Wikipedia's List of Logical Fallacies). I'm (roughly) using Information is Beautiful's categories from the [Rhetological Fallacies][] overview.

[^poster]: I'd also like to draw attention to the hilarious double-standard and endorsement of dishonest signalling in the text at the bottom of the poster.

# Genetic Fallacy (Appeal to Authority / Tradition / Majority)

Annoys me the most.

I have my own pet political theory why invoking this argument is so important to skeptics (note that the appeal to authority, tradition and popular opinion are all versions of the genetic fallacy, which is therefore represented 4 times on the poster), but I'll leave it out for now. (\*cough\*Protestantism\*cough\*)

# Argument from Ignorance / Incredulity



# Argument from Consequences

If it were true, it would have disastrous consequences, therefore it can't be true.

# Naturalistic Fallacy

# Anecdotal Evidence

# Composition / Division

And as [The Mythical Man-Month][] observed, adding more programmers to a late project will only make it later.

# Gambler's Fallacy

This, I speculate straight out my ass, is actually caused by gamblers using a [Kolmogorov-ish predictor][Kolmogorov Complexity]. They recognize that patterns are unusual, and so a coin coming up heads 5 times in a row points to something weird going on. If you can rule out deliberate manipulation, then you should see "more random" results. Another heads would *not* be random. Appealing to a base-rate probability ("The probability of heads is always 1/2, so history doesn't matter.") is flawed for this reason.

The problem is therefore one of ambiguous language. The gambler isn't making a claim about randomness[^random] in the prior probabilities sense, but the information theory sense. And assuming an ordered universe, it really *is* more reasonable to use this assumption.

That doesn't mean this fallacy doesn't exist. Just read any discussion board about a game with random drops and you'll have plenty of examples. But simply dismissing it as "people don't think about base rates" misleads you. People have an intuitive grasp of complexity and predictability, not of frequencies.

# Slippery Slope

# Strawman

# Special Pleading

# False Dilemma / False Middle Ground



# Begging the Question

Perfectly valid criticism.

# Ad Hominem

Of course, given the importance of status, this is actually a perfectly valid line of argument in many real-world situations. Look, political debates don't *really* change the world, and whatever "side" wins doesn't actually matter, so ignoring the arguments and going for the character of the opponent is *more* appropriate. If you're after tribal alliances, then you damn well care about personal character.

# Correlation vs. Causation / Post Hoc Ergo Propter Hoc

# No True Scotsman

# Tu Quoque

# Appeal to Emotion

Emotions didn't spontaneously manifest out of nowhere. They reflect evolutionary optimizations. An Appeal to Emotion is therefore often an implicit Outside View argument.

"This food looks disgusting, it must be unhealthy" is perfectly valid when you understand disgust as being strongly entangled with pathogens.

# Burden of Proof

Bayesianism.

Conclusion
==========

Following the skeptics, you'd quite often go horribly wrong. Saying "That's a logical fallacy!" and stopping there would make you miss an awful lot of things. A healthier alternative, it seems to me, would be to say "Your argument can't work as-stated, so your statement - but not the argument or conclusion - is likely broken or ambiguous.".

I fear that reading about logical fallacies itself screws you over. You are presented with a logical structure and an obvious flaw in it, like "If A, then B. B is horrible. Therefore not A.", and you then mistakenly start to believe that whenever you see this pattern, you simply see equally-incorrect ideas. It's similar to the Principle of Explosion. In Classical Logic, any contradiction implies any arbitrary statement equally. So once you notice a contradiction, you are done, nothing that follows can be trusted at all.

But that's not how the world works. Contradictions are actually localized and have relative strengths. When astronomers applied Newton's Laws, they quickly realized that Uranus' orbit didn't match the calculations. They didn't conclude from this contradiction that the Laws of Motion implied everything and were entirely worthless. Rather, they looked for localized explanations and discovered Neptune.

Similarly, it's entirely correct to say that *technically*, just because something is traditional doesn't mean it's a good idea. From the perspective of Classical Logic, that's a straightforward thing to say. But dismiss tradition, and before you know it, you're a Utopian Socialist. (And we remember how that worked out.) What you *should* have realized is that "X is traditional, therefore X" isn't what someone using an appeal to tradition is actually trying to say. They are making a claim about historical filters ("If it could work, why haven't we seen it work already?") and are taken an Outside View, and that should not be ignored.

You should not be thinking in terms of logical contradictions, but derivations from a predictive model. A "contradiction" isn't about exploding implications, but about additional complexity to your theory. If you notice that Uranus isn't where it's supposed to be[^uranus], that means that you would have to make the Laws of Motion more complex. Denying the "implication" that the laws are "false", and looking for an alternative set of conditions that would preserve the theory (like another planet) is *not* a rationalization, but a move in favor of low algorithmic complexity.

[^random]: Tee hee, I'm so random, my biography has Kolmogorov complexity equal to its length.

[^uranus]: Yo mamma so dumb, she thought rigid designators were the nicknames men give their penis.
